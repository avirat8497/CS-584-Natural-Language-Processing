{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pickle import dump\n",
    "from unicodedata import normalize\n",
    "import string\n",
    "from pickle import load\n",
    "import collections\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load doc into memory\n",
    "def load_doc(filename):\n",
    "    file = open(filename)\n",
    "    text = file.read()\n",
    "    file.close()\n",
    "    return text\n",
    " \n",
    "# split a loaded document into sentences\n",
    "def to_sentences(doc):\n",
    "    return doc.strip().split('\\n')\n",
    " \n",
    "# clean a list of lines\n",
    "def clean_lines(lines):\n",
    "    cleaned = list()\n",
    "    re_print = re.compile('[^%s]' % re.escape(string.printable))\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    for line in lines:\n",
    "        line = normalize('NFD', line).encode('ascii', 'ignore')\n",
    "        line = line.decode('UTF-8')\n",
    "        line = line.split()\n",
    "        line = [word.lower() for word in line]\n",
    "        line = [word.translate(table) for word in line]\n",
    "        line = [re_print.sub('', w) for w in line]\n",
    "        line = [word for word in line if word.isalpha()]\n",
    "        cleaned.append(' '.join(line))\n",
    "    return cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_clean_sentences(sentences, filename):\n",
    "    dump(sentences, open(filename, 'wb'))\n",
    "    print('Saved: %s' % filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: czech.txt\n",
      "nasledny postup na zaklade usneseni parlamentu viz zapis\n",
      "predlozeni dokumentu viz zapis\n",
      "pisemna prohlaseni clanek jednaciho radu viz zapis\n",
      "texty smluv dodane radou viz zapis\n",
      "slozeni parlamentu viz zapis\n",
      "clenstvi ve vyborech a delegacich viz zapis\n",
      "budouci akce v oblasti patentu predlozene navrhy usneseni viz zapis\n",
      "porad jednani pristiho zasedani viz zapis\n",
      "ukonceni zasedani\n",
      "la seduta e tolta alle\n"
     ]
    }
   ],
   "source": [
    "filename = 'europarl-v7.cs-en.cs'\n",
    "doc = load_doc(filename)\n",
    "sentences_cs= to_sentences(doc)\n",
    "sentences_cs = clean_lines(sentences_cs)\n",
    "print(sentences_cs)\n",
    "save_clean_sentences(sentences_cs, 'czech.txt')\n",
    "for i in range(10):\n",
    "    print(sentences_cs[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: english.txt\n",
      "action taken on parliaments resolutions see minutes\n",
      "documents received see minutes\n",
      "written statements rule see minutes\n",
      "texts of agreements forwarded by the council see minutes\n",
      "membership of parliament see minutes\n",
      "membership of committees and delegations see minutes\n",
      "future action in the field of patents motions for resolutions tabled see minutes\n",
      "agenda for next sitting see minutes\n",
      "closure of sitting\n",
      "the sitting was closed at pm\n"
     ]
    }
   ],
   "source": [
    "filename = 'europarl-v7.cs-en.en'\n",
    "doc = load_doc(filename)\n",
    "sentences_en = to_sentences(doc)\n",
    "sentences_en = clean_lines(sentences_en)\n",
    "save_clean_sentences(sentences_en, 'english.txt')\n",
    "# spot check\n",
    "for i in range(10):\n",
    "    print(sentences_en[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "english = list(sentences_en)\n",
    "czech = list(sentences_cs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(list1, list2): \n",
    "    merged_list = [(list1[i], list2[i]) for i in range(0, 200)] \n",
    "    return merged_list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = merge(english,czech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-9f39e613f81c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mn_sentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10000\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_dataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn_sentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# random shuffle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# split into train/test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "n_sentences = 10000\n",
    "dataset = raw_dataset[:n_sentences, :]\n",
    "# random shuffle\n",
    "shuffle(dataset)\n",
    "# split into train/test\n",
    "train, test = dataset[:9000], dataset[9000:]\n",
    "# save\n",
    "save_clean_data(dataset, 'english-german-both.pkl')\n",
    "save_clean_data(train, 'english-german-train.pkl')\n",
    "save_clean_data(test, 'english-german-test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
